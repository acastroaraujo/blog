[
  {
    "objectID": "posts/2023-12-27-what-is-computational-social-science/index.html",
    "href": "posts/2023-12-27-what-is-computational-social-science/index.html",
    "title": "What is Computational Social Science?",
    "section": "",
    "text": "I don’t think Computational Social Science (CSS) will ever become an autonomous field.\nCSS is more akin to a “trading zone” in which different disciplinary cultures manage to exchange ideas, metaphors, and techniques.1\nAs such, there’s no point in creating exclusionary boundaries around CSS. That would be bad for trade.2\nCSS is different from previous interdisciplinary efforts in that it is (1) mainly driven by advances in digital technology and (2) it is associated with a new professional group."
  },
  {
    "objectID": "posts/2023-12-27-what-is-computational-social-science/index.html#footnotes",
    "href": "posts/2023-12-27-what-is-computational-social-science/index.html#footnotes",
    "title": "What is Computational Social Science?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe idea of “trading zones” in science goes back to historian Peter Galison.↩︎\nMatt Salganik has made this point before, although for slightly different reasons; he jokingly argues that we should be happy with defining CSS simply as “anything that’s cool.” See An Introduction to Computational Social Science.↩︎\nSpector et al. (2022, p. 7) define data science as “the study of extracting value from data—value in the form of insights or conclusions.” It’s impossible to create exclusionary boundaries around such an open definition. But that should not matter as long as companies continue to recruit and students continue to enroll.↩︎\nSee Kline (2015) for cybernetics. See Thagard (2023) for cognitive science.↩︎\nTwo examples come to mind. The idea that we should pay more attention to the algorithmic component of small-world networks (Kleinberg 2000) and the idea that we should consider word embeddings as providing a template for cultural learning (Arseniev-Koehler and Foster 2022; cf. Landauer and Dumais 1997).↩︎"
  },
  {
    "objectID": "posts/2021-01-24-optimization-in-r/index.html",
    "href": "posts/2021-01-24-optimization-in-r/index.html",
    "title": "Optimization in R",
    "section": "",
    "text": "Finding the peak of parabola\n\\[y = 15 + 10x - 2x^2\\]\nFirst we write this statement as an R function.\nCode\nparabola &lt;- function(x) 15 + 10*x - 2*x^2\nThen we can visualize it using curve() or ggplot2.\nCode\nlibrary(ggplot2)\ntheme_set(theme_light(base_family = \"Optima\"))\n\ng &lt;- ggplot() + \n  geom_function(fun = parabola) +\n  xlim(0, 5) +\n  labs(x = \"x\", y = \"f(x)\")\n\ng\nThen we call optimize(), which takes the function as its first argument, the interval as its second, and an optional argument indicating whether or not you are searching for the function’s maximum (minimize is the default).\nCode\nout &lt;- optimize(parabola, interval = c(-100, 100), maximum = TRUE)\nout\n\n\n$maximum\n[1] 2.5\n\n$objective\n[1] 27.5\n\n\nCode\ng + geom_vline(xintercept = out$maximum, linetype = \"dashed\") +\n    geom_hline(yintercept = out$objective, linetype = \"dashed\")\nThere are many more ways of using optimization in R. For example, if you want to find the maximum of a function with many parameters you can use optim().\nCode\nopt &lt;- optim(\n  par = 99, ## initial values; use c(...) to do it with many parameters\n  fn = parabola, \n  method = \"BFGS\",\n  # this next line is critical: \n  # it tells R to maximize rather than minimize\n  control = list(fnscale = -1)\n)\n\nopt\n\n\n$par\n[1] 2.5\n\n$value\n[1] 27.5\n\n$counts\nfunction gradient \n       6        3 \n\n$convergence\n[1] 0\n\n$message\nNULL"
  },
  {
    "objectID": "posts/2021-01-24-optimization-in-r/index.html#logistic-regression",
    "href": "posts/2021-01-24-optimization-in-r/index.html#logistic-regression",
    "title": "Optimization in R",
    "section": "Logistic Regression",
    "text": "Logistic Regression\nIn statistics we usually try to find the maximum of likelihood functions in order to fit regression models.\nFor example1, a simple logistic regression can be fit by doing the following:\n\n\nCode\n## The dataset\ndata(\"wells\", package = \"rstanarm\")\nstr(wells)\n\n\n'data.frame':   3020 obs. of  5 variables:\n $ switch : int  1 1 0 1 1 1 1 1 1 1 ...\n $ arsenic: num  2.36 0.71 2.07 1.15 1.1 3.9 2.97 3.24 3.28 2.52 ...\n $ dist   : num  16.8 47.3 21 21.5 40.9 ...\n $ assoc  : int  0 0 0 0 1 1 1 0 1 1 ...\n $ educ   : int  0 0 10 12 14 9 4 10 0 0 ...\n\n\nCode\n## The model\nf &lt;- formula(switch ~ dist + arsenic + dist:arsenic)\n\n## The design matrix\nX &lt;- model.matrix(f, data = wells)\ndim(X)\n\n\n[1] 3020    4\n\n\nCode\n## The outcome variable\ny &lt;- wells$switch\n\n## The log-likelihood function\nlog_likelihood &lt;- function(beta, outcome, dmat) {\n  \n  linpred &lt;- dmat %*% beta ## the linear predictor\n  p &lt;- plogis(linpred)     ## the link function\n  \n  sum(dbinom(outcome, size = 1, prob = p, log = TRUE))  ## the log-likelihood\n}\n\n## The maximum likelihood estimate (MLE)\nopt &lt;- optim(\n  par = rep(0, ncol(X)), ## initial values are all 0's\n  fn = log_likelihood, method = \"BFGS\",\n  outcome = y, dmat = X,\n  # this next line is critical: \n  # it tells R to maximize rather than minimize\n  control = list(fnscale = -1)\n)\n\nnames(opt$par) &lt;- colnames(X)\nopt$par\n\n\n (Intercept)         dist      arsenic dist:arsenic \n-0.147139626 -0.005811349  0.555574583 -0.001768792 \n\n\nWe can compare this to the outcome given by R’s glm() function:\n\n\nCode\nfit &lt;- glm(f, data = wells, family = binomial(link = \"logit\"))\ncoefficients(fit)\n\n\n (Intercept)         dist      arsenic dist:arsenic \n-0.147868069 -0.005772178  0.555976744 -0.001789060"
  },
  {
    "objectID": "posts/2021-01-24-optimization-in-r/index.html#stan",
    "href": "posts/2021-01-24-optimization-in-r/index.html#stan",
    "title": "Optimization in R",
    "section": "Stan",
    "text": "Stan\nUsers of Stan should know that it can be used for optimization as well.\n\n\nCode\nlibrary(cmdstanr)\nmcmc_optim &lt;- cmdstan_model(\"simple_parabola.stan\")\nmcmc_optim$print()\n\n\nparameters {\n  real&lt;lower=0&gt; x; // easily does constrained optimization\n}\n\nmodel {\n  target += 15 + 10*x - 2*x^2;\n}\n\n\nCode\nfit &lt;- mcmc_optim$optimize()\n\n\nInitial log joint probability = 17.7521 \n    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes  \n       4          27.5    0.00019008   2.86238e-06           1           1       12    \nOptimization terminated normally:  \n  Convergence detected: relative gradient magnitude is below tolerance \nFinished in  0.3 seconds.\n\n\nCode\nfit\n\n\n variable estimate\n     lp__    27.50\n     x        2.50"
  },
  {
    "objectID": "posts/2021-01-24-optimization-in-r/index.html#footnotes",
    "href": "posts/2021-01-24-optimization-in-r/index.html#footnotes",
    "title": "Optimization in R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe data: «A survey of 3020 residents in a small area of Bangladesh suffering from arsenic contamination of groundwater. Respondents with elevated arsenic levels in their wells had been encouraged to switch their water source to a safe public or private well in the nearby area and the survey was conducted several years later to learn which of the affected residents had switched wells»↩︎"
  },
  {
    "objectID": "posts/2024-01-02-what-is-usa-sociology/index.html",
    "href": "posts/2024-01-02-what-is-usa-sociology/index.html",
    "title": "What is Sociology in the USA?",
    "section": "",
    "text": "Sociologists in the USA like describing sociology as the most heterogeneous social science of all, which is\n\n…perhaps another way of saying that it has been less successful at institutionalizing itself as a discipline than its close relatives. Unlike economics, it does not have a core kit of analytical tools and models codified in textbooks and widely accepted as legitimate both inside and outside the field… Unlike political science, on the other hand, sociology does not have a well-defined empirical core to unify it, either.\nHealy (2012, p. 88)\n\nThere are two ways of looking at this.\nGlass Half-Full\nAndrew Abbott (2001) claims sociology’s defining characteristic is “the fact that the discipline is not very good at excluding things from itself.” Some see this as something good because it turns sociology into some miniature version of all social science. In this view, the lack of “internal cohesion” in the discipline is interpreted as the cost we’ve paid in exchange for occupying a central place in the social science landscape (Moody and Light 2006).\nMany celebrate the lack of a disciplinary core as providing some unique form of academic freedom.\nThis is the reason why many people claim they haven chosen to become sociologists.\n\nI chose sociology because more than any other social science sociology would let me do what I pleased. If I went into sociology, I wouldn’t have to make up my mind what to do.\n—Andrew Abbott\nWhy, then, did I choose sociology as an academic home?\nOf all the available social sciences, sociology seemed to me to be the least disciplinary; it had the fuzziest boundaries. But even more significantly, sociology has valued its own marginal traditions in a way that other social sciences don’t.\n—Erik Olin Wright\n\nGlass Half-Empty\nOthers are less optimistic.\nPresumably, we are not as interdisciplinary as we would like to believe.\n\n…most sociologists don’t really get interdisciplinarity. Whether we acknowledge it or not, most of us have internalized a sociological supremacy that makes us believe our field’s insights are more important, more complete, more nuanced than those of other scientists (Healy 2017). This cultural background of intellectual superiority helps create what Lizardo (2014) called the “Comtean schema”—the implicit belief that all proper interdisciplinary research should take the institutional form of a subfield of sociology.\nIn a brilliant insight, Lizardo noted that sociologists create virtual “avatars” of other disciplines within sociology instead of working with their real-world counterparts. That is, rather than engage with economists, we create “economic sociology”; rather than engage with political science, we have “political sociology”; rather than engage with cultural evolution or cognitive science, we invent “the sociology of culture and cognition,” and so on. This fools us into thinking that we’re being interdisciplinary when, in reality, “[t]hese subdisciplinary avatars have been created by sociologists for sociological consumption” (Lizardo 2014:985).\nVaisey (2021, p. 1298)"
  },
  {
    "objectID": "posts/2024-01-02-what-is-usa-sociology/index.html#background",
    "href": "posts/2024-01-02-what-is-usa-sociology/index.html#background",
    "title": "What is Sociology in the USA?",
    "section": "",
    "text": "Sociologists in the USA like describing sociology as the most heterogeneous social science of all, which is\n\n…perhaps another way of saying that it has been less successful at institutionalizing itself as a discipline than its close relatives. Unlike economics, it does not have a core kit of analytical tools and models codified in textbooks and widely accepted as legitimate both inside and outside the field… Unlike political science, on the other hand, sociology does not have a well-defined empirical core to unify it, either.\nHealy (2012, p. 88)\n\nThere are two ways of looking at this.\nGlass Half-Full\nAndrew Abbott (2001) claims sociology’s defining characteristic is “the fact that the discipline is not very good at excluding things from itself.” Some see this as something good because it turns sociology into some miniature version of all social science. In this view, the lack of “internal cohesion” in the discipline is interpreted as the cost we’ve paid in exchange for occupying a central place in the social science landscape (Moody and Light 2006).\nMany celebrate the lack of a disciplinary core as providing some unique form of academic freedom.\nThis is the reason why many people claim they haven chosen to become sociologists.\n\nI chose sociology because more than any other social science sociology would let me do what I pleased. If I went into sociology, I wouldn’t have to make up my mind what to do.\n—Andrew Abbott\nWhy, then, did I choose sociology as an academic home?\nOf all the available social sciences, sociology seemed to me to be the least disciplinary; it had the fuzziest boundaries. But even more significantly, sociology has valued its own marginal traditions in a way that other social sciences don’t.\n—Erik Olin Wright\n\nGlass Half-Empty\nOthers are less optimistic.\nPresumably, we are not as interdisciplinary as we would like to believe.\n\n…most sociologists don’t really get interdisciplinarity. Whether we acknowledge it or not, most of us have internalized a sociological supremacy that makes us believe our field’s insights are more important, more complete, more nuanced than those of other scientists (Healy 2017). This cultural background of intellectual superiority helps create what Lizardo (2014) called the “Comtean schema”—the implicit belief that all proper interdisciplinary research should take the institutional form of a subfield of sociology.\nIn a brilliant insight, Lizardo noted that sociologists create virtual “avatars” of other disciplines within sociology instead of working with their real-world counterparts. That is, rather than engage with economists, we create “economic sociology”; rather than engage with political science, we have “political sociology”; rather than engage with cultural evolution or cognitive science, we invent “the sociology of culture and cognition,” and so on. This fools us into thinking that we’re being interdisciplinary when, in reality, “[t]hese subdisciplinary avatars have been created by sociologists for sociological consumption” (Lizardo 2014:985).\nVaisey (2021, p. 1298)"
  },
  {
    "objectID": "posts/2024-01-02-what-is-usa-sociology/index.html#data",
    "href": "posts/2024-01-02-what-is-usa-sociology/index.html#data",
    "title": "What is Sociology in the USA?",
    "section": "Data",
    "text": "Data\nNote. The visualization provided below is provisional. I will need to email someone at the ASA and politely ask for permission to use the directory.\nWhen a sociologist joins the American Sociological Association (ASA), they have the options to choose up to four “areas of interest” for everyone else to see. For example, I chose (1) Theory; (2) Quantitative Methodology; (3) Organizations, Formal and Complex; and (4) Law and Society. And I would probably have chosen something different on a different day.\nSo, I created a dataset containing the areas of interest of over 1,000 individuals associated with 20 sociology programs in the USA. This dataset is provisional, but see Table 1 in case you are curious about the sample.\nEach of these individuals chose anywhere between one and four areas of interest. Figure 1 highlights the ten largest areas of interest in blue. The largest is Stratification/ Mobility, which gives credence to the idea that inequality defines the subject-matter of sociology. Among the top ten we also find what some may describe as subdisciplinary avatars—Cultural Sociology, Economic Sociology, and Political Sociology—which gives credence to the idea that sociology is a miniature version of all social science. Furthermore, the idea that sociology is mostly concerned with race, class, and gender is also well represented in this top ten.\n\n\n\n\n\nFigure 1: Areas of interest in the dataset. The largest 10 areas are highlighted in blue.\n\n\n\n\nHowever, this doesn’t provide us with any information of the “structure” of the sociological areas of interest—i.e., the pattern of connections which some may describe as coherency. This is what the next section is all about."
  },
  {
    "objectID": "posts/2024-01-02-what-is-usa-sociology/index.html#two-mode-networks",
    "href": "posts/2024-01-02-what-is-usa-sociology/index.html#two-mode-networks",
    "title": "What is Sociology in the USA?",
    "section": "Two-Mode Networks",
    "text": "Two-Mode Networks\nThe direct ties between individuals and areas can be transmogrified—via simple matrix multiplication —into indirect ties among areas (Breiger 1974; Agneessens and Everett 2013). This idea should be familiar to everyone who chose Social Networks as area of interest.\n\ntransmogrification is not the “technical” term for this\n\nTo do this, we arrange the individuals and their corresponding areas in matrix form. Here, we have a matrix \\(\\mathbf X\\) with 1112 rows (one for each individual) and 61 columns (one for each area). Each cell \\(x_{ij}\\) is either a \\(1\\) or a \\(0\\). Then we transform \\(\\mathbf X\\) into a new adjacency matrix \\(\\mathbf A\\) with each cell \\(a_{ij}\\) corresponding to the number of “shared” or “intersecting” individuals between areas \\(i\\) and \\(j\\).\n\\[\n\\mathbf{A} = \\mathbf{X}^\\top \\mathbf{X}\n\\tag{1}\\]\nThe diagonal of \\(\\mathbf A\\) contains the total number of individuals that chose each area, which corresponds to the same numbers in Figure 1.1\nUnfortunately, the resulting network, is very dense. It takes only one single individual with idiosyncratic tastes to create ties among four otherwise disconnected areas. As a result, the “structure” is one in which every area is seemingly connected to every other area.2\nBecause of this issue, researchers have looked for ways to “trim” uninformative ties. The intuition is straightforward. If the observed number of shared individuals between two areas ( \\(a_{ij}\\) ) exceeds the number we would expect to see in a random network (the null model), then we draw a tie between area \\(i\\) and area \\(j\\).\nIn other words, we do a “hypothesis test” for each tie in the network depicted by \\(\\mathbf A\\). If the links between individuals and areas of interest was random, the resulting network would consist entirely of isolated nodes."
  },
  {
    "objectID": "posts/2024-01-02-what-is-usa-sociology/index.html#results",
    "href": "posts/2024-01-02-what-is-usa-sociology/index.html#results",
    "title": "What is Sociology in the USA?",
    "section": "Results",
    "text": "Results\nThe results of this procedure are shown in Figure 2, with a significance level of 0.01.\nI used Zachary Neal’s (2022) backbone package to do all this.3\nAs we may have expected, there are strong connections between Stratification/ Mobility and Education, Demography and Family, Medical Sociology and Mental Health, and so on.\nThe strong overlap between Cultural Sociology and so-called Theory deserves its own rant blogpost.\nAll isolate nodes have been removed. Keep in mind that a bigger sample of individuals and their areas would obviously result in more connected areas.\n\n\n\n\n\nFigure 2: “Strong” Ties ( α = 0.01 )\n\n\n\nFigure 3 uses a significance level of \\(0.05\\), which means we get to extract more ties and have less isolate areas.\nQuantitative Methodology now appears connected to three areas (Stratification/ Mobility, Demography, and Mathematical Sociology) but Qualitative Methodology is nowhere to be seen yet. This does not mean that one is more important than the other. It just means that the connections between Qualitative Methodology and other areas are more compatible with a “null model” of random ties between areas; whereas people who express an interest in Quantitative Methodology are more likely to express an interest in those three areas than what we would expect by chance.\nThe area of Ethnography (Anthropology)—which has about half the amount of individuals as Qualitative Methodology—has a connection to Urban Sociology, reflecting a long tradition of urban ethnographies.\nAlso, note the appearance of three areas connected around criminology.\n\n\n\n\n\nFigure 3: “Strongish” Ties ( α = 0.05 )\n\n\n\nFinally, Figure 4 uses a significance level of \\(0.06\\), just enough for connections between smaller areas to start showing up (e.g., Marxist Sociology, Alcohol and Drugs).\nPlease keep in mind that this does not mean that these connections are somehow “weaker” than the other ones in any substantive way. Hypothesis testing is extremely dependent on sample size.\n\n\n\n\n\nFigure 4: “Strongish” Ties ( α = 0.06 )\n\n\n\nThat’s all for now."
  },
  {
    "objectID": "posts/2024-01-02-what-is-usa-sociology/index.html#sample",
    "href": "posts/2024-01-02-what-is-usa-sociology/index.html#sample",
    "title": "What is Sociology in the USA?",
    "section": "Sample",
    "text": "Sample\n\n\n\n\n\n\n\n  \n    \n      Universities and Individuals\n    \n    \n    \n      \n      n\n      %\n    \n  \n  \n    Northwestern University\n84\n7.55%\n    University of Michigan-Ann Arbor\n76\n6.83%\n    University of Chicago\n72\n6.47%\n    Harvard University\n69\n6.21%\n    University of Wisconsin-Madison\n68\n6.12%\n    Stanford University\n66\n5.94%\n    University of Pennsylvania\n66\n5.94%\n    Cornell University\n65\n5.85%\n    Brown University\n62\n5.58%\n    New York University\n61\n5.49%\n    Princeton University\n59\n5.31%\n    Columbia University\n47\n4.23%\n    UC Berkeley\n46\n4.14%\n    Ohio State University\n45\n4.05%\n    Duke University\n42\n3.78%\n    Yale University\n42\n3.78%\n    University of California-Los Angeles\n41\n3.69%\n    University of North Carolina-Chapel Hill\n36\n3.24%\n    Indiana University-Bloomington\n33\n2.97%\n    University of Texas-Austin\n32\n2.88%\n    Total\n1,112\n100%\n  \n  \n  \n\nTable 1:  Number of individuals extracted from the ASA member directory"
  },
  {
    "objectID": "posts/2024-01-02-what-is-usa-sociology/index.html#citation",
    "href": "posts/2024-01-02-what-is-usa-sociology/index.html#citation",
    "title": "What is Sociology in the USA?",
    "section": "Citation",
    "text": "Citation\nThe backbone package automatically outputs the following suggest citation text:\n\nFigure 2:\nWe used the backbone package for R (v2.1.2; Neal, 2022) to extract the unweighted backbone of a weighted and undirected unipartite network containing 61 nodes. An edge was retained in the backbone if its weight was statistically significant (alpha = 0.01) using the disparity filter (Serrano et al., 2009). This reduced the number of edges by 99%, and reduced the number of connected nodes by 68.9%.\nFigure 3:\nWe used the backbone package for R (v2.1.2; Neal, 2022) to extract the unweighted backbone of a weighted and undirected unipartite network containing 61 nodes. An edge was retained in the backbone if its weight was statistically significant (alpha = 0.05) using the disparity filter (Serrano et al., 2009). This reduced the number of edges by 96.3%, and reduced the number of connected nodes by 34.4%.\nFigure 4:\nWe used the backbone package for R (v2.1.2; Neal, 2022) to extract the unweighted backbone of a weighted and undirected unipartite network containing 61 nodes. An edge was retained in the backbone if its weight was statistically significant (alpha = 0.06) using the disparity filter (Serrano et al., 2009). This reduced the number of edges by 94.9%, and reduced the number of connected nodes by 21.3%.\nNeal, Z. P. 2022. backbone: An R Package to Extract Network Backbones. PLOS ONE, 17, e0269137. https://doi.org/10.1371/journal.pone.0269137\nSerrano, M. A., Boguna, M., & Vespignani, A. (2009). Extracting the multiscale backbone of complex weighted networks. Proceedings of the National Academy of Sciences, 106(16), 6483-6488. https://doi.org/10.1073/pnas.0808904106"
  },
  {
    "objectID": "posts/2024-01-02-what-is-usa-sociology/index.html#footnotes",
    "href": "posts/2024-01-02-what-is-usa-sociology/index.html#footnotes",
    "title": "What is Sociology in the USA?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis new matrix \\(\\mathbf A\\) is sometimes called a two-mode or bipartite projection. The original network represented by \\(\\mathbf X\\) goes by many names—e.g, affiliation network, bipartite graph, two-mode network, etc.↩︎\nKnoke et al. (2021) [pp. 36] note three problems with using this sort of projection. First, it entails a loss of “identity information” on one of the two node sets—e.g., the cell entries in \\(\\mathbf A\\) don’t reveal the specific individuals shared across areas. Second, it results in very dense networks, which leads to biases in network measurements—e.g., an artificially high number of triangles (see Opsahl 2013). Third, it obscures the generative process behind tie formation.↩︎\nThe threshold level here is arbitrary, this is a blogpost. The “disparity filter” algorithm was chosen because it was the fastest, this is a blogpost.\n\nThe choice of algorithm and threshold level is rarely discussed in most publications of this sort, so I guess I’m sort of following tradition here.↩︎"
  },
  {
    "objectID": "posts/2022-01-01-regression-to-the-mean/index.html",
    "href": "posts/2022-01-01-regression-to-the-mean/index.html",
    "title": "Regression to the Mean",
    "section": "",
    "text": "Regression to the mean is one of the greatest parables in statistics. The term originated in 1886, when Francis Galton was studying hereditary patterns in human populations. While he was studying the association between children’s and parent’s heights, he noticed that tall (short) parents tend to have children shorter (taller) than themselves; and that they tended towards a population average.\n\npar-a-ble: A simple story used to illustrate a moral or spiritual lesson, as told by Jesus in the Gospels.\n\n\n\nCode\nHistData::Galton |&gt; \n  ggplot(aes(x = parent, y = child)) + \n  geom_jitter(alpha = 0.5) +\n  ## line of equality\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\", linewidth = 1) +\n  ## regression line\n  geom_smooth(method = lm, se = FALSE, color = \"skyblue\") \n\n\n\n\n\n\n\n\n\nThis is the data originally analyzed by Galton himself. The dashed line represents equality, meaning that parents and children have the same height. But Galton noted that children’s heights were actually closer to the blue prediction line.\n\nSee Stigler (2016).\n\nThe key insight is that, whenever randomness is involved, the more extreme outcomes will tend to be followed by more moderate outcomes. Why? Because part of the reason these outcomes are so extreme in the first place is due to randomness. Galton also termed this phenomena “regression to mediocrity”1.\nNowadays, we would look at this same problem using linear regression, which allows us to put the predicted heights of children into a simple formula.\n\n\nCode\nd &lt;- HistData::Galton |&gt; \n  mutate(parent_centered = parent - mean(parent))\n\nOLS &lt;- lm(child ~ parent_centered, data = d) ## scaling\n\ncoefficients(OLS)\n\n\n    (Intercept) parent_centered \n     68.0884698       0.6462906 \n\n\nNote that the heights of parents have been centered in order to produce an intercept that corresponds to the population average (or “mediocrity”).\n\\[\n\\widehat h_\\text{child} =  \\underbrace{68.09}_\\text{mediocrity} + 0.65 \\times \\widetilde h_\\text{parent}\n\\]\nAt first encounter, some people will interpret this as meaning that regression to the mean implies that heights will become “more average” over time. Thus, a parent who is 5 inches above average is predicted to have children 3.2 inches taller than average, who in turn are predicted to have children 2.1 inches taller than average, and so on. This very common misunderstanding arises from neglecting the error term when thinking about future observations.\n\\[\nh_\\text{child} = \\widehat h_\\text{child} + \\text{error}\n\\]\nIn Gelman et al’s words:\n\nThe point predictions regress toward the mean—that’s the coefficient less than 1—and this reduces variation. At the same time, though, the error in the model—the imperfection of the prediction—adds variation, just enough to keep the total variation in height roughly constant from one generation to the next.\nRegression to the mean thus will always arise in some form whenever predictions are imperfect in a stable environment. The imperfection of the prediction induces variation, and regression in the point prediction is required in order to keep the total variation constant.\nGelman et al. (2020, p. 88)\n\nThe following graphs show both ways of interpreting regression to the mean, based on how the data could look like across 12 generations:\n\n\nCode\nOLS &lt;- lm(child ~ parent, data = HistData::Galton)\nintercept &lt;- coefficients(OLS)[[1]]\nslope &lt;- coefficients(OLS)[[2]]\nsigma &lt;- sd(residuals(OLS))\n\ng0 &lt;- HistData::Galton$parent # first ancestors\n\n## Simulation\n\nreg_naive &lt;- function(x, ...) {\n  x * slope + intercept\n}\n\nreg_correct &lt;- function(x, ...) {\n  rnorm(n = length(x), mean = x * slope + intercept, sd = sigma)\n}\n\nn &lt;- 12 # number of generations\n\ns_naive &lt;- accumulate(1:n, reg_naive, .init = g0) \ns_correct &lt;- accumulate(1:n, reg_correct, .init = g0)\nnames(s_correct) &lt;- names(s_naive) &lt;- 0:n\n\ndf_naive &lt;- as_tibble(s_naive) |&gt; \n  mutate(ancestor = row_number()) |&gt; \n  pivot_longer(cols = !ancestor, names_to = \"generation\", values_to = \"height\") |&gt; \n  mutate(simulation = \"naive interpretation\", generation = as.integer(generation))\n\ndf_correct &lt;- as_tibble(s_correct) |&gt; \n  mutate(ancestor = row_number()) |&gt; \n  pivot_longer(cols = !ancestor, names_to = \"generation\", values_to = \"height\") |&gt; \n  mutate(simulation = \"correct interpretation\", generation = as.integer(generation))\n\nbind_rows(df_correct, df_naive) |&gt; \n  ggplot(aes(x = generation, y = height, color = ancestor, group = ancestor)) +\n  geom_line(show.legend = FALSE, alpha = 1/10) +\n  facet_wrap(~ simulation, ncol = 1, scales = \"free_y\") + \n  labs(y = \"height (inches)\") + \n  scale_color_viridis_c() +\n  scale_x_continuous(breaks = 0:12) +\n  theme(strip.text.x = element_text(size = 14)) \n\n\n\n\n\n\n\n\n\n\nThis very simple simulation assumes that the population average remains constant over time, which is obviously false when you consider changes in public health, such as nutrition.\nAs a general rule, nothing in the social and biological sciences remains constant over very long periods of time."
  },
  {
    "objectID": "posts/2022-01-01-regression-to-the-mean/index.html#origin-story",
    "href": "posts/2022-01-01-regression-to-the-mean/index.html#origin-story",
    "title": "Regression to the Mean",
    "section": "",
    "text": "Regression to the mean is one of the greatest parables in statistics. The term originated in 1886, when Francis Galton was studying hereditary patterns in human populations. While he was studying the association between children’s and parent’s heights, he noticed that tall (short) parents tend to have children shorter (taller) than themselves; and that they tended towards a population average.\n\npar-a-ble: A simple story used to illustrate a moral or spiritual lesson, as told by Jesus in the Gospels.\n\n\n\nCode\nHistData::Galton |&gt; \n  ggplot(aes(x = parent, y = child)) + \n  geom_jitter(alpha = 0.5) +\n  ## line of equality\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\", linewidth = 1) +\n  ## regression line\n  geom_smooth(method = lm, se = FALSE, color = \"skyblue\") \n\n\n\n\n\n\n\n\n\nThis is the data originally analyzed by Galton himself. The dashed line represents equality, meaning that parents and children have the same height. But Galton noted that children’s heights were actually closer to the blue prediction line.\n\nSee Stigler (2016).\n\nThe key insight is that, whenever randomness is involved, the more extreme outcomes will tend to be followed by more moderate outcomes. Why? Because part of the reason these outcomes are so extreme in the first place is due to randomness. Galton also termed this phenomena “regression to mediocrity”1.\nNowadays, we would look at this same problem using linear regression, which allows us to put the predicted heights of children into a simple formula.\n\n\nCode\nd &lt;- HistData::Galton |&gt; \n  mutate(parent_centered = parent - mean(parent))\n\nOLS &lt;- lm(child ~ parent_centered, data = d) ## scaling\n\ncoefficients(OLS)\n\n\n    (Intercept) parent_centered \n     68.0884698       0.6462906 \n\n\nNote that the heights of parents have been centered in order to produce an intercept that corresponds to the population average (or “mediocrity”).\n\\[\n\\widehat h_\\text{child} =  \\underbrace{68.09}_\\text{mediocrity} + 0.65 \\times \\widetilde h_\\text{parent}\n\\]\nAt first encounter, some people will interpret this as meaning that regression to the mean implies that heights will become “more average” over time. Thus, a parent who is 5 inches above average is predicted to have children 3.2 inches taller than average, who in turn are predicted to have children 2.1 inches taller than average, and so on. This very common misunderstanding arises from neglecting the error term when thinking about future observations.\n\\[\nh_\\text{child} = \\widehat h_\\text{child} + \\text{error}\n\\]\nIn Gelman et al’s words:\n\nThe point predictions regress toward the mean—that’s the coefficient less than 1—and this reduces variation. At the same time, though, the error in the model—the imperfection of the prediction—adds variation, just enough to keep the total variation in height roughly constant from one generation to the next.\nRegression to the mean thus will always arise in some form whenever predictions are imperfect in a stable environment. The imperfection of the prediction induces variation, and regression in the point prediction is required in order to keep the total variation constant.\nGelman et al. (2020, p. 88)\n\nThe following graphs show both ways of interpreting regression to the mean, based on how the data could look like across 12 generations:\n\n\nCode\nOLS &lt;- lm(child ~ parent, data = HistData::Galton)\nintercept &lt;- coefficients(OLS)[[1]]\nslope &lt;- coefficients(OLS)[[2]]\nsigma &lt;- sd(residuals(OLS))\n\ng0 &lt;- HistData::Galton$parent # first ancestors\n\n## Simulation\n\nreg_naive &lt;- function(x, ...) {\n  x * slope + intercept\n}\n\nreg_correct &lt;- function(x, ...) {\n  rnorm(n = length(x), mean = x * slope + intercept, sd = sigma)\n}\n\nn &lt;- 12 # number of generations\n\ns_naive &lt;- accumulate(1:n, reg_naive, .init = g0) \ns_correct &lt;- accumulate(1:n, reg_correct, .init = g0)\nnames(s_correct) &lt;- names(s_naive) &lt;- 0:n\n\ndf_naive &lt;- as_tibble(s_naive) |&gt; \n  mutate(ancestor = row_number()) |&gt; \n  pivot_longer(cols = !ancestor, names_to = \"generation\", values_to = \"height\") |&gt; \n  mutate(simulation = \"naive interpretation\", generation = as.integer(generation))\n\ndf_correct &lt;- as_tibble(s_correct) |&gt; \n  mutate(ancestor = row_number()) |&gt; \n  pivot_longer(cols = !ancestor, names_to = \"generation\", values_to = \"height\") |&gt; \n  mutate(simulation = \"correct interpretation\", generation = as.integer(generation))\n\nbind_rows(df_correct, df_naive) |&gt; \n  ggplot(aes(x = generation, y = height, color = ancestor, group = ancestor)) +\n  geom_line(show.legend = FALSE, alpha = 1/10) +\n  facet_wrap(~ simulation, ncol = 1, scales = \"free_y\") + \n  labs(y = \"height (inches)\") + \n  scale_color_viridis_c() +\n  scale_x_continuous(breaks = 0:12) +\n  theme(strip.text.x = element_text(size = 14)) \n\n\n\n\n\n\n\n\n\n\nThis very simple simulation assumes that the population average remains constant over time, which is obviously false when you consider changes in public health, such as nutrition.\nAs a general rule, nothing in the social and biological sciences remains constant over very long periods of time."
  },
  {
    "objectID": "posts/2022-01-01-regression-to-the-mean/index.html#the-lesson",
    "href": "posts/2022-01-01-regression-to-the-mean/index.html#the-lesson",
    "title": "Regression to the Mean",
    "section": "The lesson",
    "text": "The lesson\nRegression to the mean will people to see causality where there is none.\nAs mentioned earlier, this phenomena shows up all the time wherever randomness (or “luck”) is expected to play a role. Thus, we see it in everything from sports to public policy.2 This is a problem because human beings are inclined to find amazing patterns when they look at randomness. Obviously, this is mostly harmless when, for example, the source of randomness is clouds in the sky and the patterns we find take the form of “a cow” or “a face.”3 But in other settings, this same phenomena can become worrisome.\nAn exercise in simulation4\nA very famous real-world example is contained in an article titled “On the psychology of prediction” Tversky & Kahneman, 1973):\n\nThe instructors in a flight school adopted a policy of consistent positive reinforcement recommended by psychologists. They verbally reinforced each successful execution of a flight maneuver. After some experience with this training approach, the instructors claimed that contrary to psychological doctrine, high praise for good execution of complex maneuvers typically results in a decrement of performance on the next try. What should the psychologist say in response?\n\nTo answer this question we simulate data from 500 pilots, each of whom performs two maneuvers, and with each maneuver scored continuously on a 0-10 scale. Each pilot has a “true ability” that is unchanged during the two tasks, and the score for each test is equal to this true ability plus an independent error. Pilots get praised when they score higher than 7 during the first maneuver, and receive negative reinforcement when they score lower than 3.\nThe connection between this example and Galton’s study is not obvious at first glance. Here, each pilot’s score exhibits regression to her “true ability”, in the sense that we expect “luck” to play an important role. As before, we don’t really expect these “true abilities” to remain constant over time. In fact that would defeat the entire purpose of flight school. But we do expect these underlying abilities to change very slowly.\nNote that we make sure, by design, that reinforcement has no effect on performance on the second task.\n\n\nCode\nN &lt;- 500\ntrue_abilities &lt;- rnorm(N, 0, 1)\n# mapping the true abilities + random noise to a [0,10] scale\ntask1 &lt;- plogis(true_abilities + rnorm(N, 0, 0.5)) * 10\ntask2 &lt;- plogis(true_abilities + rnorm(N, 0, 0.5)) * 10\n\ndf &lt;- tibble(true_abilities, task1, task2) |&gt; \n  mutate(reinforcement = case_when(\n    task1 &lt; 3 ~ \"negative\",\n    task1 &gt; 7 ~ \"positive\",\n    TRUE ~ \"neutral\")\n  )\n\ndf |&gt; \n  ggplot(aes(x = task1, y = task2, color = reinforcement)) +\n  geom_point() +\n  scale_color_manual(values = c(\"pink\", \"grey\", \"skyblue\")) +\n  scale_x_continuous(breaks = seq(2, 10, 2)) +\n  scale_y_continuous(breaks = seq(2, 10, 2))\n\n\n\n\n\nWe can now compute the average change in scores for each group of pilots, which the instructors interpret to be the causal effect of reinforcement.\n\n\nCode\ndf |&gt; \n  mutate(change = task2 - task1) |&gt; \n  group_by(reinforcement) |&gt; \n  summarise(\n    effect = mean(change),\n    se = sd(change) / sqrt(n())\n    ) |&gt; \n  ggplot(aes(x = reinforcement, y = effect)) +\n  geom_pointrange(aes(\n    ymin = effect + qnorm(p = 0.025)*se,\n    ymax = effect + qnorm(p = 0.975)*se\n    )) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  coord_flip()\n\n\n\n\n\nNotice that, on average, the pilots who were praised did worse on the second task, whereas the pilots who received negative reinforcement did better. But we know that such effect doesn’t exist. And we know this because we created these data so that task 1 and task 2 were unrelated. The “causal pattern” we have just observed is a consequence of the noise in the data. Pilots who scored very well on task 1 are likely to have a higher skill and also to have been somewhat lucky. Thus, it makes sense that they perform slightly worse on task 2.\nThis is how Tversky and Kahneman (1982) explain it:\n\nRegression is inevitable in flight maneuvers because performance is not perfectly reliable and progress between successive maneuvers is slow. Hence, pilots who did exceptionally well on one trial are likely to deteriorate on the next, regardless of the instructors’ reaction to the initial success. The experienced flight instructors actually discovered the regression but attributed it to the detrimental effect of positive reinforcement. This true story illustrates a saddening aspect of the human condition. We normally reinforce others when their behavior is good and punish them when their behavior is bad. By regression alone, therefore, they are most likely to improve after being punished and most likely to deteriorate after being rewarded. Consequently, we are exposed to a lifetime schedule in which we are most often rewarded for punishing others, and punished for rewarding.\nQuoted in Gelman et al. (2020, p. 90)"
  },
  {
    "objectID": "posts/2022-01-01-regression-to-the-mean/index.html#footnotes",
    "href": "posts/2022-01-01-regression-to-the-mean/index.html#footnotes",
    "title": "Regression to the Mean",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHistorically, there have been two kinds moral judgments regarding averages and normal distributions (Hacking 1990): (1) the Quetelet-Durkheim conception of the normal as the right and the good; and (2) Galton’s notion of the normal as the mediocre, and in need of improvement.↩︎\nThis also seems to be the reason why so many bands appear to suffer from “second album syndrome” or “sophomore slump”.↩︎\nSee: pareidolia.↩︎\nThis my solution to exercise 6.8 in Regression and Other Stories.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "blog",
    "section": "",
    "text": "What is Sociology in the USA?\n\n\n\n\n\n\n\nSociology\n\n\nNetworks\n\n\n\n\nA visualization.\n\n\n\n\n\n\nJan 2, 2024\n\n\nandrés castro araújo\n\n\n\n\n\n\n  \n\n\n\n\nData\n\n\n\n\n\n\n\nPhilosophy\n\n\nStatistics\n\n\n\n\nWhat is data, if not experience persevering?\n\n\n\n\n\n\nDec 31, 2023\n\n\nandrés castro araújo\n\n\n\n\n\n\n  \n\n\n\n\nWhat is Computational Social Science?\n\n\n\n\n\n\n\nSocial Science\n\n\nComputation\n\n\n\n\nIt is a trading zone driven by digital technology and associated with a new professional group.\n\n\n\n\n\n\nDec 27, 2023\n\n\nandrés castro araújo\n\n\n\n\n\n\n  \n\n\n\n\nDistributions in R\n\n\n\n\n\n\n\nR\n\n\nProbability\n\n\n\n\nA short tutorial.\n\n\n\n\n\n\nMay 12, 2022\n\n\nandrés castro araújo\n\n\n\n\n\n\n  \n\n\n\n\nTheory-Work\n\n\n\n\n\n\n\nTheory\n\n\nSociology\n\n\n\n\nDeepities, social constructionism, and sociological theory.\n\n\n\n\n\n\nFeb 7, 2022\n\n\nandrés castro araújo\n\n\n\n\n\n\n  \n\n\n\n\nRegression to the Mean\n\n\n\n\n\n\n\nStatistics\n\n\nCausality\n\n\n\n\nA visual explanation.\n\n\n\n\n\n\nJan 1, 2022\n\n\nandrés castro araújo\n\n\n\n\n\n\n  \n\n\n\n\nOptimization in R\n\n\n\n\n\n\n\nR\n\n\n\n\nA few different ways to do optimization.\n\n\n\n\n\n\nJan 24, 2021\n\n\nandrés castro araújo\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2022-05-12-distributions-in-r/index.html",
    "href": "posts/2022-05-12-distributions-in-r/index.html",
    "title": "Distributions in R",
    "section": "",
    "text": "Set up\nlibrary(tidyverse)\ntheme_set(\n  theme_light(base_family = \"Optima\") + \n  theme(strip.background = element_rect(fill = \"#595959\"))\n)\nR has four built-in forms of working with probability distributions.\nSee ?distributions for a list of common distributions contained in R.\nFor example, to work with a normal distribution we have the following functions:\nA common source of confusion comes from the difference between continuous random variables (e.g. a normal distribution) and discrete random variables (e.g. a binomial distribution).\nThis will all make sense."
  },
  {
    "objectID": "posts/2022-05-12-distributions-in-r/index.html#discrete-distributions",
    "href": "posts/2022-05-12-distributions-in-r/index.html#discrete-distributions",
    "title": "Distributions in R",
    "section": "discrete distributions",
    "text": "discrete distributions\nIn this section we’ll use two distributions as examples.\nThe probability distribution of a binomial random variable comes from adding coin flips (also known as Bernoulli distributions). The Bernoulli distribution has two possible outcomes \\(x = \\{0, 1\\}\\) and one parameter \\(p\\) (which confusingly is also a probability).\nFor example, let’s suppose a coin is loaded and so \\(p = 0.75\\).\nThe probability mass function (PMF) of this Bernoulli distribution is as follows:\n\\[\nf(x) = \\Pr(X = x) = \\begin{cases}\n    0.75 &\\text{if} \\ x = 1 \\\\\\\\\n    0.25 &\\text{if} \\ x = 0 \\\\\\\\\n    0 &\\text{if} \\ x = \\text{anything else}\n\\end{cases}\n\\]\nThe cumulative distribution function (CDF) is as follows:\n\\[\nF(x) = \\Pr(X \\leq x) = \\begin{cases}\n    0 &\\text{if} \\ x &lt; 1 \\\\\n    0.25 &\\text{if} \\ x = 0 \\\\\n    1  &\\text{if} \\ x = 1 \\\\\n    1 &\\text{if} \\ x &gt; 1\n\\end{cases}\n\\]\n\nNote the change in notation from \\(f\\) to \\(F\\).\n\nAny CDF returns the probability that an outcome is less than or equal to \\(x\\). In other words, you’re simply adding up the probability masses for each possible outcome until you reach \\(x\\).\nThe binomial distribution\nAs mentioned earlier, the binomial distribution comes from adding \\(n\\) coin flips. For example, if you throw 3 coins then we have four possible outcomes \\(x = \\{0, 1, 2, 3\\}\\) and two parameters: \\(p\\) and \\(n = 3\\).\nThe probability (mass) function of this binomial distribution is then this:\n\\[\nf(x) = \\Pr(X = x) = \\begin{cases}\n    1 \\ (1 - p)^3 &\\text{if} \\ x = 0 \\\\\n    3 \\ p(1 - p)^2 &\\text{if} \\ x = 1 \\\\\n    3 \\ p^2(1-p) &\\text{if} \\ x = 2 \\\\\n    1\\ p^3 &\\text{if} \\ x = 3 \\\\\n    0 &\\text{if} \\ x = \\text{anything else}\n\\end{cases}\n\\]\nThe 1s and 3s come from counting the number of ways in which \\(x\\) can equal one of these numbers. This is not different from “the garden of forking data” stuff in McElreath (2020, pp. 20–27)\nBut this is not how you’ll see binomial distributions written out in the wild. We need new notation in order to write any binomial distribution, which we get by using the binomial coefficient:\n\\[\n{n \\choose x} = \\frac{n!}{x! (n - x)!}\n\\]\nSo the probability (mass) function of any binomial distribution is then this:\n\\[\nf(x) = \\Pr(X = x) = {n \\choose x} p^x (1-p)^{n-x}\n\\]\nThe cumulative distribution function is as follows:\n\\[\nF(x) = \\Pr(X \\leq x) = \\sum_{i = 0}^x {n \\choose x} p^x (1-p)^{n-x}\n\\]\nFor example, with \\(n = 10\\) and \\(p = 0.5\\), this is how they look:\n\n\nCode\ntibble(x = 0:10) |&gt; \n  mutate(\n    \"Probability Mass Function — dbinom(x, size = 10, p = 1/2)\" = \n      dbinom(x, size = 10, p = 1/2),\n    \"Cumulative Distribution Function — pbinom(x, size = 10, p = 1/2)\" = \n      pbinom(x, size = 10, p = 1/2)\n  ) |&gt;\n  mutate(x = factor(x)) |&gt; \n  pivot_longer(!x, names_to = \"distribution\") |&gt; \n  ggplot(aes(x, value)) + \n  geom_col(width = 1/3) +\n  facet_wrap(~distribution, ncol = 1) + \n  labs(y = NULL)\n\n\n\n\n\nNote that the Bernoulli distribution is now a special case of the binomial distribution in which \\(n = 1\\).\nThis is what’s going on when you use the dbinom and pbinom functions:\nThe Bernoulli PMF is the same as the binomial PMF with \\(n = 1\\)\n\n\nCode\ndbinom(x = c(-2, -1, 0, 1, 2, 3), size = 1, prob = 0.75)\n\n\n[1] 0.00 0.00 0.25 0.75 0.00 0.00\n\n\nBernoulli CDF\n\n\nCode\npbinom(q = c(-2, -1, 0, 1, 2, 3), size = 1, prob = 0.75)\n\n\n[1] 0.00 0.00 0.25 1.00 1.00 1.00\n\n\nBinomial PMF with \\(n=4\\)\n\n\nCode\ndbinom(x = seq(-1, 5), size = 4, prob = 0.75)\n\n\n[1] 0.00000000 0.00390625 0.04687500 0.21093750 0.42187500 0.31640625 0.00000000\n\n\nBinomial CDF with \\(n=4\\)\n\n\nCode\npbinom(q = seq(-1, 5), size = 4, prob = 0.75)\n\n\n[1] 0.00000000 0.00390625 0.05078125 0.26171875 0.68359375 1.00000000 1.00000000\n\n\nNote that because pbinom is just adding different pieces of dbinom together, we could have obtained the same results simply by adding.\nBinomial CDF with \\(n = 4\\)\n\n\nCode\ncumsum(dbinom(x = seq(-1, 5), size = 4, prob = 0.75))\n\n\n[1] 0.00000000 0.00390625 0.05078125 0.26171875 0.68359375 1.00000000 1.00000000\n\n\nDrawing random samples\nrbinom is used to draw samples from dbinom. This makes doing math very easy. For example, suppose we have 12 coin flips—or a binomial distribution with \\(n = 12\\) and \\(p = 0.5\\).\n\n\nCode\ndraws &lt;- rbinom(n = 1e4, size = 12, prob = 0.5) \n\n\nWhat is the probability that \\(x = 7\\)?\n\n\nCode\nmean(draws == 7)  ## approx\n\n\n[1] 0.1928\n\n\nCode\ndbinom(x = 7, size = 12, prob = 0.5)\n\n\n[1] 0.1933594\n\n\nWhat is the probability that \\(x \\leq 8\\)?\n\n\nCode\nmean(draws &lt;= 8)  ## approx\n\n\n[1] 0.9298\n\n\nCode\npbinom(q = 8, size = 12, prob = 0.5)\n\n\n[1] 0.927002\n\n\nWhat is the probability that \\(x\\) is \\(1\\) or \\(4\\) or \\(9\\)?\n\n\nCode\nmean(draws %in% c(1, 4, 9)) ## approx\n\n\n[1] 0.1785\n\n\nCode\nsum(dbinom(x = c(1, 4, 9), size = 12, prob = 0.5))\n\n\n[1] 0.1774902"
  },
  {
    "objectID": "posts/2022-05-12-distributions-in-r/index.html#continuous-distributions",
    "href": "posts/2022-05-12-distributions-in-r/index.html#continuous-distributions",
    "title": "Distributions in R",
    "section": "continuous distributions",
    "text": "continuous distributions\nThe well-known probability (density) distribution for a normal random variable has two parameters \\(\\mu\\) and \\(\\sigma^2\\).\nIt’s ugly:\n\\[\nf(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp\\bigg(- \\frac{(x - \\mu)^2}{2 \\sigma^2}\\bigg)\n\\]\nNote that \\(f(x) \\neq \\Pr(X = x)\\).\nBecause \\(x\\) is a real number (that ranges from \\(-\\infty\\) to \\(+\\infty\\)), the probability that \\(x = 1\\) is exactly the same as the probability that \\(x = 0.9999...\\) both are zero.\n\n\nCode\nggplot() + \n  xlim(-5, 5) + \n  geom_function(fun = dnorm) + \n  labs(y = \"density\", x = \"x\")\n\n\n\n\n\nHowever, the cumulative distribution function (CDF) does have the same interpretation. If you add all the possible values until you reach \\(x\\) you get \\(\\Pr(X \\leq x)\\). BUT, because there exists an infinite amount of numbers between \\(-\\infty\\) and \\(x\\), you can’t simply add. You have to integrate.\n\\[\nF(x) = \\Pr(X \\leq x) = \\int_{-\\infty}^x f(x) dx\n\\]\n\n\nCode\nggplot() + \n  xlim(-5, 5) + \n  geom_function(fun = pnorm) + \n  labs(y = \"cumulative probability\", x = \"x\")\n\n\n\n\n\nAssuming \\(\\mu = 0\\) and \\(\\sigma = 2\\), what is the probability that \\(x\\) is less than or equal to zero?\nThe following two chunks of code give the same answer:\n\n\nCode\npnorm(q = 0, mean = 0, sd = 2)\n\n\n[1] 0.5\n\n\nCode\nintegrate(dnorm, lower = -Inf, upper = 0, mean = 0, sd = 2)\n\n\n0.5 with absolute error &lt; 7.3e-07\n\n\nYou can also get an approximate answer by drawing random samples with rnorm.\n\n\nCode\ndraws &lt;- rnorm(1e5, mean = 0, sd = 2)\nmean(draws &lt;= 0) ## approx\n\n\n[1] 0.49917\n\n\nKnowing that the CDF is an integral, we can understand the PDF as the derivative of the CDF. (The derivative of an integral of a function is just the function itself). In other words, a probability density is the rate of change in cumulative probability at \\(x\\). The PDF is the “slope” of the CDF at \\(x\\). This means that if the cumulative probability is increasing rapidly, the density can easily exceed 1. But if we calculate the area under the density function, it will never exceed 1.\n\nSee the “overthinking” section in McElreath (2020, p. 76) for a similar description of this issue.\n\nFor example, compare the PDF and CDF of the exponential distribution. While the CDF eventually converges to 1, the density easily exceeds 1 at some points.\nCDF:\n\n\nCode\nggplot() + \n  xlim(0, 5) + \n  geom_function(fun = function(x) pexp(x, rate = 3)) + \n  labs(y = \"cumulative probability\", x = \"x\")\n\n\n\n\n\nPDF:\n\n\nCode\nggplot() + \n  xlim(0, 5) + \n  geom_function(fun = function(x) dexp(x, rate = 3)) +\n  labs(y = \"density\", x = \"x\")\n\n\n\n\n\nMore examples:\n\n\nCode\ndraws &lt;- rnorm(1e4, mean = 2, sd = 5)\n\n\nWhat is the probability that \\(x = 7\\)?\n\n\nCode\nmean(draws == 7)  ## approx\n\n\n[1] 0\n\n\nWhat is the probability that \\(3 &lt; x &lt; 7\\)?\n\n\nCode\nintegrate(dnorm, mean = 2, sd = 5, lower = 3, upper = 7)\n\n\n0.262085 with absolute error &lt; 2.9e-15\n\n\nCode\nmean(3 &lt; draws & draws &lt; 7)\n\n\n[1] 0.2657\n\n\nWhat is the probability that \\(x \\leq 8\\)?\n\n\nCode\nmean(draws &lt;= 8)  ## approx\n\n\n[1] 0.8861\n\n\nCode\npnorm(8, mean = 2, sd = 5)\n\n\n[1] 0.8849303\n\n\nWhat is the probability that \\(x\\) is NOT between \\(-2\\) and \\(2\\)?\n\n\nCode\n1 - integrate(dnorm, mean = 2, sd = 5, lower = -2, upper = 2)$value\n\n\n[1] 0.7118554\n\n\nCode\nmean(draws &lt; -2 | draws &gt; 2)  ## approx\n\n\n[1] 0.7112"
  },
  {
    "objectID": "posts/2022-05-12-distributions-in-r/index.html#quantile-functions",
    "href": "posts/2022-05-12-distributions-in-r/index.html#quantile-functions",
    "title": "Distributions in R",
    "section": "quantile functions",
    "text": "quantile functions\nThe inverse of a CDF is called a quantile function (\\(Q = F^{-1}\\)).\nThis is where we get stuff like the median:\n\\[\n\\underbrace{Q(0.5)}_\\text{median} = x \\iff \\Pr(X \\leq x) = 0.5\n\\]\nMedian example with the exponential distribution:\n\n\nCode\nqexp(p = 0.5, rate = 3)         ## finding the median\n\n\n[1] 0.2310491\n\n\nCode\npexp(q = 0.2310491, rate = 3)   ## verifying the median\n\n\n[1] 0.5000001\n\n\nCode\ndraws &lt;- rexp(1e5, rate = 3)    ## finding the median using random draws\nquantile(draws, 0.5)            ## approx\n\n\n      50% \n0.2317321"
  },
  {
    "objectID": "posts/2023-12-31-data/index.html",
    "href": "posts/2023-12-31-data/index.html",
    "title": "Data",
    "section": "",
    "text": "Data, plural for the Latin word datum.\nI find it useful to distinguish between data and phenomena.\n\nPhenomena: recurrent features of the world.\nData: “public records produced by measurement and experiment that serve as evidence for the existence or features of phenomena” (Woodward 2011, p. 166)\nEven in well-designed experiments, the data will reflect the influence of many other causal factors that have nothing to do with the phenomena of interest.\n\nBut there’s more.\nWhen we think about “data” we generally think about standardized data—i.e., symbols that are arranged in a way that’s convenient for computer processing. We think about symbols that are stable, manipulable, and transportable—or what Bruno Latour (1987) calls “immutable and combinable mobiles.”\nNote. Accepting a distinction between data and phenomena means that we can have different explanations for the phenomena (scientific models) and for the observed data (statistical models). The most obvious examples of this distinction are statistical models whose purpose is to account for some form of measurement error or to impute missing data. All variables are measured with error. The distinction becomes less clear when we start thinking about “bespoke statistical models” (McElreath 2020, chap. 16).\n\n\n\n\n\n\n\n\n\nReferences\n\nLatour, Bruno. 1987. Science in Action: How to Follow Scientists and Engineers Through Society. Harvard University Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in r and Stan. CRC press.\n\n\nWoodward, James F. 2011. “Data and Phenomena: A Restatement and Defense.” Synthese 182: 165179."
  },
  {
    "objectID": "posts/2022-02-07-theory-work/index.html",
    "href": "posts/2022-02-07-theory-work/index.html",
    "title": "Theory-Work",
    "section": "",
    "text": "Theoretical work should strive, among other things, “to improve the precision, clarity, and coherence of our ideas” (Martin 2014).\nThis involves cultivating some good habits.\nFor example,\n\nOne important habit for theorizing is just the following: as one writes a period at the end of the sentence, to stop and ask oneself “am I sure this is true? Let me entertain the opposite. Do I have any reason to reject it other than my desire to go forward with my own argument?”\nMartin (2014, pp. 10–11)\n\nSometimes it involves avoiding common traps—e.g., the three “nuance traps” described by Kieran Healy (2017).\n\nFirst is the ever more detailed, merely empirical description of the world. This is the nuance of the fine-grain. It is a rejection of theory masquerading as increased accuracy. Second is the ever more extensive expansion of some theoretical system in a way that effectively closes it off from rebuttal or disconfirmation by anything in the world. This is the nuance of the conceptual framework. It is an evasion of the demand that a theory be refutable. And third is the insinuation that a sensitivity to nuance is a manifestation of one’s distinctive (often metaphorically expressed and at times seemingly ineffable) ability to grasp and express the richness, texture, and flow of social reality itself. This is the nuance of the connoisseur. It is mostly a species of self-congratulatory symbolic violence\nHealy (2017, pp. 120–21)\n\nRelatedly, sociologists will sometimes stretch their concepts to fit new cases in such a way that brings about the careless redefinition of important terms. For example, Martin (2014) cites Niklas Luhmann saying that “All meaninglessness… has meaning again through its strangeness.” The statement is only true if we accept a new definition for the word meaning. And why should we?\n\nMost generally, whenever we find ourselves rushing to claim that “things outside of any set are themselves in the set” we may be changing our terminology in ways we do not understand. And if we make a habit of it, we’ll end up using meaningless statements.\nMartin (2014, p. 13)\n\nIn short, good theory-work should give us the tools to avoid common traps. It should enable us to tell apart good nuance (e.g. getting important details correct, avoiding oversimplifications) from bad nuance. It should enable us to tell apart good empirical tautologies (e.g., “people try to be good, and good is what ever people say is good”) from bad argumentative tautologies (i.e., assuming at one place what we are claiming to prove at another)."
  },
  {
    "objectID": "posts/2022-02-07-theory-work/index.html#deepities",
    "href": "posts/2022-02-07-theory-work/index.html#deepities",
    "title": "Theory-Work",
    "section": "Deepities",
    "text": "Deepities\nGood theory-work should also prevent us from saying deepities.\n\nA deepity is a proposition that seems both important and true —and profound— but that achieves this effect by being ambiguous. On one reading it is manifestly false, but it would be earth-shaking if it were true; on the other reading it is true but trivial. The unwary listener picks up the glimmer of truth from the second reading, and the devastating importance from the first reading, and thinks, Wow! That’s a deepity.\nDennett (2013, p. 56)\n\n\nDennett’s favorite example is love is just a word.\n\nIn other words, good theory-work should constrain our thinking so that saying stupid things becomes much harder.\n\nConstructionist arguments are not deepities\nDeepities are found all over social science and the humanities, in the sense that ambiguous statements will get rewarded if they seem profound. A lot of constructionist arguments, for example, become deepities when they take the form “\\(X\\) is socially constructed, therefore \\(X\\) is not real”.\nBut most sociologists often take the opposite perspective: “\\(X\\) is real because it’s socially constructed”.1\nThe logic behind constructionist arguments is fairly straightforward.\n\nSocial constructionists about \\(X\\) tend to hold that:\n\n\\(X\\) need not have existed, or need not be at all as it is. \\(X\\), or \\(X\\) as it is at present, is not determined by the nature of things; it is not inevitable.\n\nVery often they go further, and urge that:\n\n\\(X\\) is quite bad as it is.\nWe would be much better off if \\(X\\) were done away with, or at least radically transformed.\n\nHacking (1999, p. 6)\n\nThis kind of argument is not trivial when \\(X\\) is taken for granted—i.e., when \\(X\\) appears to be inevitable. Take the notion of racecraft, which is used to describe how social hierarchy gets projected into “nature” in the form of “race.”\n\nConsider the statement “black Southerners were segregated because of their skin color”—a perfectly natural sentence to the ears of most Americans, who tend to overlook its weird causality.\nFields and Fields (2014, p. 17)\n\nHow can skin color cause segregation? How can skin color cause a stop-and-frisk incident?\nIn a way, this is the opposite of Dennet’s “deepity.” It is a statement that looks trivial and true at first glance. But, upon closer reflection, it has no well-formed meaning. And if it were true, it would have earth shattering consequences to our conception of causality. Which begs the question: why did it originally seem so unremarkable?\nAt their most ambitious, social constructionist arguments are an indictment of folk social theory (or “the culture”). They remind us that many arbitrary things come to be seen as “natural” or “inevitable” in the course of everyday life."
  },
  {
    "objectID": "posts/2022-02-07-theory-work/index.html#footnotes",
    "href": "posts/2022-02-07-theory-work/index.html#footnotes",
    "title": "Theory-Work",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is what drove Durkheim to speak of social facts and it’s what drives contemporary sociologists to speak of institutions.↩︎"
  }
]